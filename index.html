<h1>AI Fairness, Accountability & Diversity Assessment</h1>

<h2>Problem</h2>
<ul>
  <li>Organisations struggle to identify fairness/accountability risks in real AI deployments.</li>
  <li>Standards (ISO 42005/42001) do not fully cover stakeholder inclusion and transparency gaps.</li>
</ul>

<h2>Approach</h2>
<ul>
  <li>Comparative analysis of standards</li>
  <li>Framework development: Stakeholder Insight Map, Fairness/Accountability Gap Model</li>
  <li>Bias and risk identification method</li>
</ul>

<h2>Key Findings</h2>
<ul>
  <li>Limited stakeholder representation increases fairness risks.</li>
  <li>Accountability gaps come from unclear responsibility boundaries.</li>
  <li>Diverse perspectives reveal overlooked risk scenarios.</li>
</ul>

<h2>My Contribution</h2>
<ul>
  <li>Designed analytical models and evaluation logic</li>
  <li>Structured risk identification framework</li>
  <li>Integrated DEI-focused assessment flow</li>
</ul>

<p>LinkedIn: https://www.linkedin.com/in/takeru-sonoda/</p>
